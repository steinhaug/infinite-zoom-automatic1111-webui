{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steinhaug/infinite-zoom-automatic1111-webui/blob/main/smooth_infinite_zoom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bynW8jh187Wq",
      "metadata": {
        "id": "bynW8jh187Wq"
      },
      "source": [
        "## A user friendly colab notebook to generate infinite loop videos in minutes (works on free colab plan)\n",
        "\n",
        "#### Examples and latest version available here:  \n",
        "https://colab.research.google.com/github/steinhaug/infinite-zoom-automatic1111-webui/blob/main/smooth_infinite_zoom.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oIZQ7ADVr8Bf",
      "metadata": {
        "cellView": "form",
        "id": "oIZQ7ADVr8Bf"
      },
      "outputs": [],
      "source": [
        "#@markdown CHECK TYPE OF GPU AND VRAM AVAILABLE   <br>\n",
        "#@markdown The notebook should work fine with the Tesla T4 GPU + 16 GB VRAM available (but to a limited extend) in the free colab plan. <br>\n",
        "#@markdown If this drops an error you need go: Runtime / Change runtime type and pick Hardvare accelarator = GPU and GPU class = Standard.\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70157fc1",
      "metadata": {
        "id": "70157fc1"
      },
      "outputs": [],
      "source": [
        "#@markdown **Static setting**\n",
        "from google.colab import drive\n",
        "from types import SimpleNamespace\n",
        "\n",
        "def Static():\n",
        "    mount_google_drive = True #@param {type:\"boolean\"}\n",
        "    if (mount_google_drive) : \n",
        "      drive.mount('/content/gdrive')\n",
        "    output_path = \"/content/gdrive/MyDrive/infinite-zoom\" #@param {type:\"string\"}\n",
        "    return locals()\n",
        "\n",
        "static = Static()\n",
        "static = SimpleNamespace(**static)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VYc3IHgCTs3E",
      "metadata": {
        "id": "VYc3IHgCTs3E"
      },
      "outputs": [],
      "source": [
        "#@markdown SET UP ENVIRONMENT\n",
        "\n",
        "print(\"1/3: Install missing libraries\")\n",
        "%pip install -qq transformers scipy ftfy accelerate\n",
        "%pip install -qq --upgrade diffusers[torch]\n",
        "\n",
        "print(\"2/3: Load necessary libraries\")\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "import torch\n",
        "from diffusers import StableDiffusionInpaintPipeline, DPMSolverMultistepScheduler\n",
        "from IPython.display import clear_output\n",
        "from datetime import datetime\n",
        "if not os.path.exists(static.output_path):\n",
        "    os.makedirs(static.output_path)\n",
        "print(\"3/3: Define helper functions\")\n",
        "def write_video(file_path, frames, fps, reversed = True, start_frame_dupe_amount = 15, last_frame_dupe_amount = 30):\n",
        "  \"\"\"\n",
        "  Writes frames to an mp4 video file\n",
        "  :param file_path: Path to output video, must end with .mp4\n",
        "  :param frames: List of PIL.Image objects\n",
        "  :param fps: Desired frame rate\n",
        "  :param reversed: if order of images to be reversed (default = True)\n",
        "  \"\"\"\n",
        "  if reversed == True:\n",
        "    frames.reverse()\n",
        "\n",
        "  w, h = frames[0].size\n",
        "  fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
        "  #fourcc = cv2.VideoWriter_fourcc('h', '2', '6', '4')\n",
        "  #fourcc = cv2.VideoWriter_fourcc(*'avc1')\n",
        "  writer = cv2.VideoWriter(file_path, fourcc, fps, (w, h))\n",
        "\n",
        "## start frame duplicated \n",
        "  for x in range(start_frame_dupe_amount):  \n",
        "    np_frame = np.array(frames[0].convert('RGB'))\n",
        "    cv_frame = cv2.cvtColor(np_frame, cv2.COLOR_RGB2BGR)\n",
        "    writer.write(cv_frame)\n",
        "  \n",
        "  for frame in frames:\n",
        "      np_frame = np.array(frame.convert('RGB'))\n",
        "      cv_frame = cv2.cvtColor(np_frame, cv2.COLOR_RGB2BGR)\n",
        "      writer.write(cv_frame)\n",
        "\n",
        "## last frame duplicated \n",
        "  for x in range(last_frame_dupe_amount):  \n",
        "    np_frame = np.array(frames[len(frames) - 1].convert('RGB'))\n",
        "    cv_frame = cv2.cvtColor(np_frame, cv2.COLOR_RGB2BGR)\n",
        "    writer.write(cv_frame)\n",
        "    \n",
        "  writer.release() \n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "  assert len(imgs) == rows*cols\n",
        "\n",
        "  w, h = imgs[0].size\n",
        "  grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "  grid_w, grid_h = grid.size\n",
        "\n",
        "  for i, img in enumerate(imgs):\n",
        "      grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "  return grid\n",
        "\n",
        "def shrink_and_paste_on_blank(current_image, mask_width):\n",
        "  \"\"\"\n",
        "  Decreases size of current_image by mask_width pixels from each side,\n",
        "  then adds a mask_width width transparent frame, \n",
        "  so that the image the function returns is the same size as the input. \n",
        "  :param current_image: input image to transform\n",
        "  :param mask_width: width in pixels to shrink from each side\n",
        "  \"\"\"\n",
        "\n",
        "  height = current_image.height\n",
        "  width = current_image.width\n",
        "\n",
        "  #shrink down by mask_width\n",
        "  prev_image = current_image.resize((height-2*mask_width,width-2*mask_width))\n",
        "  prev_image = prev_image.convert(\"RGBA\")\n",
        "  prev_image = np.array(prev_image)\n",
        "\n",
        "  #create blank non-transparent image\n",
        "  blank_image = np.array(current_image.convert(\"RGBA\"))*0\n",
        "  blank_image[:,:,3] = 1\n",
        "\n",
        "  #paste shrinked onto blank\n",
        "  blank_image[mask_width:height-mask_width,mask_width:width-mask_width,:] = prev_image\n",
        "  prev_image = Image.fromarray(blank_image)\n",
        "\n",
        "  return prev_image\n",
        "  \n",
        "def load_img(address, res=(512, 512)):\n",
        "    if address.startswith('http://') or address.startswith('https://'):\n",
        "        image = Image.open(requests.get(address, stream=True).raw)\n",
        "    else:\n",
        "        image = Image.open(address)\n",
        "    image = image.convert('RGB')\n",
        "    image = image.resize(res, resample=Image.LANCZOS)\n",
        "    return image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbdb396d-f01c-4b4b-9307-b0f78eaa9ffd",
      "metadata": {
        "cellView": "form",
        "id": "bbdb396d-f01c-4b4b-9307-b0f78eaa9ffd"
      },
      "outputs": [],
      "source": [
        "#@markdown DOWNLOAD MODEL WEIGHTS AND SET UP DIFFUSION PIPELINE <br><br>\n",
        "#@markdown Pick your favourite inpainting model:\n",
        "model_id = 'stabilityai/stable-diffusion-2-inpainting' #@param [\"stabilityai/stable-diffusion-2-inpainting\", \"runwayml/stable-diffusion-inpainting\", \"ImNoOne/f222-inpainting-diffusers\",\"parlance/dreamlike-diffusion-1.0-inpainting\",\"ghunkins/stable-diffusion-liberty-inpainting\"] {allow-input: true}\n",
        "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        ")\n",
        "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "def dummy(images, **kwargs):\n",
        "    return images, False\n",
        "pipe.safety_checker = dummy\n",
        "pipe.enable_attention_slicing() #This is useful to save some memory in exchange for a small speed decrease.\n",
        "\n",
        "g_cuda = torch.Generator(device='cuda')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddf0d121",
      "metadata": {
        "id": "ddf0d121"
      },
      "outputs": [],
      "source": [
        "prompts={\n",
        "    0: \"metropolis cybernetic cyberpunk snowcrash neuromancer soft pastel colors, wizarth, imagevectorism, portrait, Gothic Art by Kenny Schink, Softcore watercolor DEMONIC Messiah MEDUSA statue ARTFULL colors Instagram trending ARTstation beautiful symmetric symmetry horrifically brutal\",\n",
        "    7: \"Ultra realistic astronaut on the beach fantastically detailed reflecting eyes modern anime style art massive detailed built-in firearms wolfmask cyborg male leather jacket suit, beam sword, missile, shoulder cannon, four arms, vtuber cyberpunk,\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e53e31ca-0992-425b-ba26-3906e4a974d6",
      "metadata": {
        "cellView": "form",
        "id": "e53e31ca-0992-425b-ba26-3906e4a974d6"
      },
      "outputs": [],
      "source": [
        "#@markdown FIND A GOOD CONCEPT FOR YOUR VIDEO: <br>\n",
        "#@markdown (Image output of this block will be the last image of the video)\n",
        "\n",
        "prompt = prompts[0]\n",
        "negative_prompt = \"montage, frame, text, ugly, blur\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Number of initial example images to generate:\n",
        "num_init_images = 2 #@param\n",
        "#@markdown Random seed (arbitrary input to make the initial image generation deterministic):\n",
        "seed = 9999 #@param\n",
        "#@markdown  The number of denoising steps (Higher number usually lead to a higher quality image at the expense of slower inference):\n",
        "num_inference_steps = 30 #@param\n",
        "#@markdown Guidance scale defines how closely generated images to be linked to the text prompt:\n",
        "guidance_scale = 6 #@param\n",
        "#@markdown Heigth (and width) of the images in pixels (= resolution of the video generated in the next block, has to be divisible with 8):\n",
        "height = 512 #@param\n",
        "width = height \n",
        "#@markdown Since the model was trained on 512 images increasing the resolution to e.g. 1024 will\n",
        "#@markdown drastically reduce its imagination, so the video will vary a lot less compared to 512\n",
        "\n",
        "current_image = PIL.Image.new(mode=\"RGBA\", size=(height, width))\n",
        "mask_image = np.array(current_image)[:,:,3] \n",
        "mask_image = Image.fromarray(255-mask_image).convert(\"RGB\")\n",
        "current_image = current_image.convert(\"RGB\")\n",
        "\n",
        "init_images =  pipe(prompt=[prompt]*num_init_images,\n",
        "                    negative_prompt=[negative_prompt]*num_init_images,\n",
        "                    image=current_image,\n",
        "                    guidance_scale = guidance_scale,\n",
        "                    height = height,\n",
        "                    width = width, \n",
        "                    generator = g_cuda.manual_seed(seed),\n",
        "                    mask_image=mask_image, \n",
        "                    num_inference_steps=num_inference_steps)[0]\n",
        "\n",
        "\n",
        "image_grid(init_images, rows=1, cols=num_init_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ThlSkJ71bUFJ",
      "metadata": {
        "id": "ThlSkJ71bUFJ"
      },
      "source": [
        "We shrink the init image from the previous block and outpaint its outer frame using the same concept defined above (e.g. prompt, negative prompt, inference steps) but with a different seed. To generate an \"inifinte zoom\" video this is repeated **num_outpainting_steps** times and then rendered in reversed order.  \n",
        "  \n",
        "To keep the outpainted part coherent and full of new content its width has to be relatively large (e.g. **mask_width** = 128 pixels if resolution is 512*512). \n",
        "   \n",
        "This on the other hand means that the generated video would be too fast and aestetically unpleasant. To slow down and smoothen the video we generate **num_interpol_frames** additional images between outpainted images using simple \"interpolation\".    \n",
        "\n",
        "Notes:    \n",
        "\n",
        " - Length of the video is proportional to num_outpainting_steps * num_interpol_frames.   \n",
        " - The time to generate the video is proportional to num_outpainting_steps.  \n",
        " - On a T4 GPU it takes about ~7 minutes to generate the video of width = 512, num_inference_steps = 20, num_outpainting_steps = 100. With fps = 24 and num_interpol_frames = 24 the video will be about 1:40 minutes long.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62b4aed2-0dae-4c39-a445-5d901e81036e",
      "metadata": {
        "cellView": "form",
        "id": "62b4aed2-0dae-4c39-a445-5d901e81036e"
      },
      "outputs": [],
      "source": [
        "#@markdown GENERATE VIDEO:  <br> <br>\n",
        "\n",
        "#@markdown Pick an initial image from the previous block for your video: <br> (This is only relevant if num_init_images > 1)\n",
        "init_image_selected = 1 #@param\n",
        "if num_init_images == 1:\n",
        "  init_image_selected = 0\n",
        "else:\n",
        "  init_image_selected = init_image_selected - 1\n",
        "custom_init_image = True #@param {type:\"boolean\"}\n",
        "init_image_address = \"/content/gdrive/MyDrive/init/image.jpeg\"#@param {type:\"string\"}\n",
        "#@markdown Number of outpainting steps:\n",
        "num_outpainting_steps = 20 #@param\n",
        "#@markdown Width of the border in pixels to be outpainted during each step:\n",
        "#@markdown <br> (make sure: mask_width < image resolution / 2)\n",
        "mask_width = 128 #@param\n",
        "#@markdown Number of images to be interpolated between each outpainting step:\n",
        "num_interpol_frames = 30 #@param \n",
        "\n",
        "if(custom_init_image):\n",
        "  current_image = load_img(init_image_address,(width,height))\n",
        "else :\n",
        "  current_image = init_images[init_image_selected]\n",
        "all_frames = []\n",
        "all_frames.append(current_image)\n",
        "\n",
        "for i in range(num_outpainting_steps):\n",
        "  print('Generating image: ' + str(i+1) + ' / ' + str(num_outpainting_steps))\n",
        "\n",
        "  prev_image_fix = current_image\n",
        "\n",
        "  prev_image = shrink_and_paste_on_blank(current_image, mask_width)\n",
        "\n",
        "  current_image = prev_image\n",
        "\n",
        "  #create mask (black image with white mask_width width edges)\n",
        "  mask_image = np.array(current_image)[:,:,3] \n",
        "  mask_image = Image.fromarray(255-mask_image).convert(\"RGB\")\n",
        "\n",
        "  #inpainting step\n",
        "  current_image = current_image.convert(\"RGB\")\n",
        "  images = pipe(prompt=prompts[max(k for k in prompts.keys() if k <= i)],\n",
        "                negative_prompt=negative_prompt,\n",
        "                image=current_image,\n",
        "                guidance_scale = guidance_scale,\n",
        "                height = height,\n",
        "                width = width, \n",
        "                #this can make the whole thing deterministic but the output less exciting\n",
        "                #generator = g_cuda.manual_seed(seed), \n",
        "                mask_image=mask_image, \n",
        "                num_inference_steps=num_inference_steps)[0]\n",
        "  current_image = images[0]\n",
        "  current_image.paste(prev_image, mask=prev_image)\n",
        "\n",
        "  #interpolation steps bewteen 2 inpainted images (=sequential zoom and crop)\n",
        "  for j in range(num_interpol_frames - 1):\n",
        "    interpol_image = current_image\n",
        "    interpol_width = round(\n",
        "        (1- ( 1-2*mask_width/height )**( 1-(j+1)/num_interpol_frames ) )*height/2 \n",
        "        )\n",
        "    interpol_image = interpol_image.crop((interpol_width,\n",
        "                                          interpol_width,\n",
        "                                          width - interpol_width,\n",
        "                                          height - interpol_width))\n",
        "\n",
        "    interpol_image = interpol_image.resize((height, width))\n",
        "\n",
        "    #paste the higher resolution previous image in the middle to avoid drop in quality caused by zooming\n",
        "    interpol_width2 = round(\n",
        "        ( 1 - (height-2*mask_width) / (height-2*interpol_width) ) / 2*height\n",
        "        )\n",
        "    prev_image_fix_crop = shrink_and_paste_on_blank(prev_image_fix, interpol_width2)\n",
        "    interpol_image.paste(prev_image_fix_crop, mask = prev_image_fix_crop)\n",
        "\n",
        "    all_frames.append(interpol_image)\n",
        "\n",
        "  all_frames.append(current_image)\n",
        "  clear_output(wait=True)\n",
        "  interpol_image.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "377b2064-7c0e-404b-8366-8d03befb840a",
      "metadata": {
        "id": "377b2064-7c0e-404b-8366-8d03befb840a"
      },
      "outputs": [],
      "source": [
        "#@markdown RENDER THE GENERATED FRAMES INTO AN MP4 VIDEO.\n",
        "video_file_name = \"infinite_zoom\" #@param {type:\"string\"}\n",
        "#@markdown frames per second:\n",
        "fps = 30 #@param\n",
        "now = datetime.now()\n",
        "date_time = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
        "#@markdown Duplicates the first and last frames, use to add a delay before animation based on playback fps (15 = 0.5 seconds @ 30fps)\n",
        "start_frame_dupe_amount = 15 #@param\n",
        "last_frame_dupe_amount = 15 #@param\n",
        "write_video(os.path.join(static.output_path, video_file_name + \"_out_\"+date_time+\".mp4\"), all_frames, fps, False, start_frame_dupe_amount, last_frame_dupe_amount)\n",
        "write_video(os.path.join(static.output_path, video_file_name + \"_in_\"+date_time+\".mp4\"), all_frames, fps, True, start_frame_dupe_amount, last_frame_dupe_amount)\n",
        "#@markdown Once this block is finished, download your video from the \"Files\" folder menu on the left (output_path)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uGFjrJkTOUZt",
      "metadata": {
        "cellView": "form",
        "id": "uGFjrJkTOUZt"
      },
      "outputs": [],
      "source": [
        "#@markdown CHECK SOME (equally spaced) FRAMES OF THE VIDEO:\n",
        "num_of_frames_to_chk = 4 #@param\n",
        "num_of_frames_to_chk = min(num_of_frames_to_chk, len(all_frames))\n",
        "idx = np.round(np.linspace(0, len(all_frames) - 1, num_of_frames_to_chk)).astype(int)\n",
        "image_grid(list(all_frames[i] for i in idx), rows = 1, cols = num_of_frames_to_chk)\n",
        "#@markdown (This is relatively slow but still faster in some cases then to download the complete video in the previous block)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "db751f19a851203103a0bb17a8ccebdb9f60364948df4a7f3512c43de08ae3e7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}